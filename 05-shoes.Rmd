# Shoes {#shoes}

## Longitudinal Shoe Study {#longitudinal}

[Github repository](https://github.com/CSAFE-ISU/Longitudinal_Shoe_Study)

### Paper describing the database

[Paper subdirectory of Github repository](https://github.com/CSAFE-ISU/Longitudinal_Shoe_Study/tree/master/Paper)

Goal: 

- Describe experiment
- Describe database function
- Publicize data for analysis by others in the community

#### Methods and Data Description {-#lss-paper-methods}
Methods and data description handed off to Alicia for editing

#### Data Analysis Tools {-#lss-paper-analysis}
- Working with the `EBImage` package - very fast processing of images

##### Film and Powder Images {-#lss-paper-analysis-film}

<img src="images/shoes/longitudinal/Film_Demo_Orig.png" width = "100%"/>

Analysis Steps:
<details>
<summary>Summary: Create a mask via thresholding, clean it up, fill in mask holes, creating a shoe "region" mask</summary>

1. Create threshold mask
    a. Blur image (circular/gaussian blur, diameter 15)    
    <img src="images/shoes/longitudinal/Film_Demo_Blur_Init.png" width = "100%"/>
    b. Invert the image    
    <img src="images/shoes/longitudinal/Film_Demo_Inv.png" width = "100%"/>
    c. Threshold image (adaptive threshold, 10 x 10 region, keep anything with an average higher than 0.025 from the mean)    
    <img src="images/shoes/longitudinal/Film_Demo_Thresh_Init.png" width = "100%"/>
    d. Create mask    
        Default parameters selected by visually screening several shoes:
        <img src="images/shoes/longitudinal/Film_Demo_Parameter_Selection.png" width = "100%"/>
        (default parameters rad1 = 5, rad2 = <span class="new">91</span>, proportion = 1.5*area of rad2 in px/area of image in px)    
    <img src="images/shoes/longitudinal/Film_Demo_Mask.png" width = "100%"/>
        1. erode mask image (circle, diameter rad1)
        2. dilate mask image (circle, diameter rad2)
        3. label disjoint regions of the image
        4. prune small image regions (area < proportion parameter)
    e. Fill in mask holes     
    <img src="images/shoes/longitudinal/Film_Demo_Hull.png" width = "100%"/>
    f. Expand mask to capture entire shoe region
    <img src="images/shoes/longitudinal/Film_Demo_Mask_Expand.png" width = "100%"/>
        1. set background color
        2. create dataframe of useful (non-background) pixels
        3. fill in holes and concave regions in mask, then expand by expand_rad vertically and horizontally (similar to "convex hull", but with additional expansion radius)
        
2. Mask image to remove extra variability unrelated to the shoe    
<img src="images/shoes/longitudinal/Film_Demo_Cleaned.png" width = "100%"/>

3. Threshold masked image?    
Con: Lose grey information; Pro: fully remove background    
<img src="images/shoes/longitudinal/Film_Demo_Cleaned_Thresh.png" width = "100%"/>

4. Compromise: Keep grey pixels from thresholded, masked image (e.g. use 3. as a mask), then renormalize    
<img src="images/shoes/longitudinal/Film_Demo_Cleaned_Balance.png" width = "100%"/>

```{r film-clean-code-demo, eval = F, include = F}
source("code/shoes/longitudinal/20190905-Film_Print_Cleaning.R")
```
</details>

<div class = "new">
I've added the functions from last week to the `ShoeScrubR` package, which will hopefully contain methods for handling all of the different 2D shoe data from the longitudinal study.

Using that package, I tried the method out on a sequence of shoes over time to see what methods might best show wear. Each column shows a single left shoe over four timepoints. The shoes are the first 9 shoeIDs (e.g. 1 - 9).  

- <details><summary>Original</summary>
<img src="images/shoes/longitudinal/Film_First9_Original.png" width="100%"/>
</details>
- <details><summary>Cleaned</summary>     
<img src="images/shoes/longitudinal/Film_First9_Cleaned.png" width="100%"/></details>
- <details><summary>Cleaned and Thresholded</summary> 
<img src="images/shoes/longitudinal/Film_First9_Cleaned_Thresholded.png" width="100%"/></details>

Even with the cleaning methods... there is a lot of extra noise. 

Next step: templating!

Basic framework: 

- <details><summary>Create a template for each size and model combination</summary>
(using GIMP - if I could automate this, I wouldn't need the template `r emo::ji("roll_eyes")`
<img src="images/shoes/longitudinal/Templates_Equal_Size.png" width = "100%"/></details>
- Goal: Maximize the number of black pixels in the image within the template region
- <details><summary>Intelligently brute force angle and position of template</summary>
Modified from @kimGrayscaleTemplateMatchingInvariant2007

1. Start with an image and a template mask

2. Blur, normalize, invert, and threshold the image    
<img src="images/shoes/longitudinal/Templates_Setup.png" width = "50%"/>

3. Naively align the "centers" of the two images (avg of white pixel row/cols). To make this calculation comparable, do some very crude dilation/erosion (that may or may not generalize that well `r emo::ji("sob")`) to fill in the image a bit.    
<img src="images/shoes/longitudinal/Templates_Naive_Centering.png" width = "50%"/>    
Then make the aligned center the actual center of the image via padding. This is the 1st time we have modified the actual image.



</details>


</div>

##### Wear Characterization {-#lss-paper-analysis-wear}
Ideas:

- average intensity of cleaned image
- length of border/edges detected


## Passive Shoe Recognition {#connor}

###CoNNOR: Convolutional Neural Network for Outsole Recognition##

**Project Overview**

  - Label images of shoes according to geometric classification scheme
  - Use convolutional base of pretrained CNN VGG16 and train a new classifier on labeled features
  - Eventually, acquire real data passively and use CoNNOR to assess feature similarities and frequencies

[Link to submitted Creative Component on CoNNOR](https://lib.dr.iastate.edu/creativecomponents/264/)

[Github repository for paper submitted to Forensic Science International](https://github.com/srvanderplas/CoNNORFSI)

**Exploring new directions:**

<div class = "new">

- Truncate convolutional base and train random forest on features
    - Could replace fully connected layers of neural net as classifier
    - Importance score can filter/reduce the number of features 
    - *Block 4 random forest training terminated after one week :( *
    - *Block 5 currently training for two different random forest packages (randomForest and ranger)*
    - *If new models take more than 1-2 weeks, will look into subsampling techniques.*
  
- *Spatial integration*
    - *Model is currently set up to take in 256x256 pixels*
    - *Try taking in full shoe using a sliding window of size 256x256*
    - *View class predictions spatially*
  
- Fully convolutional networks (FCNs)
    - Unsupervised segmentation to assess current classification scheme
    - Handle whole shoe image of any size (instead of only 256x256 pixel images)
    
</div>
    
**References for CNNs and FCNs**

[Stack Exchange post explaining patchwise training](https://stats.stackexchange.com/questions/266075/patch-wise-training-and-fully-convolutional-training-in-fully-convolutional-neur)

["Learning Hierarchical Features for Scene Labeling"](https://ieeexplore.ieee.org/abstract/document/6338939): describes an application of multi-scale CNNs and image pyramids

["Pyramid methods in image processing"](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.8646): classic paper from 1984 explaining pyramid methods

["Fully Convolutional Networks for Semantic Segmentation"](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf)

["W-Net: A Deep Model for Fully Unsupervised Image Segmentation"](https://arxiv.org/pdf/1711.08506.pdf)


## Maximum Clique Matching {#maxclique}

## Project Tread (formerly Cocoa Powder Citizen Science) {#cocoa}

<div class = "new">

Project Tread, modified from [Leverhulme Institute's Sole Searching](https://www.dundee.ac.uk/leverhulme/citizenscience/details/sole-searching.php), is a developing CSAFE project with the goals of engaging community participation in forensic research and acquiring shoe print data that may be useful in future analyses.

In progress:

- Review [procedures](https://forensicstats.org/project-tread/) and IRB documents written by James
- Perhaps modify procedures, then bribe some friends into helping me test them :)
    - Test for length, clarity, ease, etc.
- Be involved in set up of data collection site (through CSSM)

</div>

## 3d Shoe Recognition 

The set up


What we have tried 

What we are doing now 
  - Transforming the mesh objects to points aligned by the center of mass to overlay them detecting difference. 
<img src="images/shoes/3dshoes/AlignShoeTest.png" width="100%"/>
  - Problems 
    - Isnt aligning properly as you can see 
  - Next
    - angle transformations 
    

