<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Shoes | This is us: making CSAFE stronger each week</title>
  <meta name="description" content="This is our new approach of showing our progress one week at a time. This book is based on the minimal example of using the bookdown package. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.13 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Shoes | This is us: making CSAFE stronger each week" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is our new approach of showing our progress one week at a time. This book is based on the minimal example of using the bookdown package. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="csafe-isu/this-is-us" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Shoes | This is us: making CSAFE stronger each week" />
  
  <meta name="twitter:description" content="This is our new approach of showing our progress one week at a time. This book is based on the minimal example of using the bookdown package. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="CSAFE" />


<meta name="date" content="2019-09-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="glass.html"/>
<link rel="next" href="theoretical-foundations.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">This is us</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="bullets.html"><a href="bullets.html"><i class="fa fa-check"></i><b>3</b> Project CC: Bullets and Cartridge Cases</a><ul>
<li class="chapter" data-level="3.1" data-path="bullets.html"><a href="bullets.html#data-collection"><i class="fa fa-check"></i><b>3.1</b> Data Collection</a><ul>
<li class="chapter" data-level="3.1.1" data-path="bullets.html"><a href="bullets.html#lapd"><i class="fa fa-check"></i><b>3.1.1</b> LAPD</a></li>
<li class="chapter" data-level="3.1.2" data-path="bullets.html"><a href="bullets.html#hamby-sets"><i class="fa fa-check"></i><b>3.1.2</b> Hamby Sets</a></li>
<li class="chapter" data-level="3.1.3" data-path="bullets.html"><a href="bullets.html#houston-tests"><i class="fa fa-check"></i><b>3.1.3</b> Houston Tests</a></li>
<li class="chapter" data-level="3.1.4" data-path="bullets.html"><a href="bullets.html#houston-persistence"><i class="fa fa-check"></i><b>3.1.4</b> Houston Persistence</a></li>
<li class="chapter" data-level="3.1.5" data-path="bullets.html"><a href="bullets.html#st-louis-persistence"><i class="fa fa-check"></i><b>3.1.5</b> St Louis persistence</a></li>
<li class="chapter" data-level="3.1.6" data-path="bullets.html"><a href="bullets.html#dfsc-cartridge-cases"><i class="fa fa-check"></i><b>3.1.6</b> DFSC Cartridge cases</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="bullets.html"><a href="bullets.html#computational-tools"><i class="fa fa-check"></i><b>3.2</b> Computational Tools</a><ul>
<li class="chapter" data-level="3.2.1" data-path="bullets.html"><a href="bullets.html#x3ptools"><i class="fa fa-check"></i><b>3.2.1</b> x3ptools</a></li>
<li class="chapter" data-level="3.2.2" data-path="bullets.html"><a href="bullets.html#bulletxtrctr"><i class="fa fa-check"></i><b>3.2.2</b> bulletxtrctr</a></li>
<li class="chapter" data-level="3.2.3" data-path="bullets.html"><a href="bullets.html#groovefinder"><i class="fa fa-check"></i><b>3.2.3</b> grooveFinder</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="bullets.html"><a href="bullets.html#similarity-scores"><i class="fa fa-check"></i><b>3.3</b> Similarity Scores</a><ul>
<li class="chapter" data-level="3.3.1" data-path="bullets.html"><a href="bullets.html#bullet-lands"><i class="fa fa-check"></i><b>3.3.1</b> Bullet Lands</a></li>
<li class="chapter" data-level="3.3.2" data-path="bullets.html"><a href="bullets.html#cartridge-cases"><i class="fa fa-check"></i><b>3.3.2</b> Cartridge Cases</a></li>
<li class="chapter" data-level="3.3.3" data-path="bullets.html"><a href="bullets.html#modified-chumbley-non-random"><i class="fa fa-check"></i><b>3.3.3</b> Modified Chumbley non-random</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="bullets.html"><a href="bullets.html#analysis-of-results"><i class="fa fa-check"></i><b>3.4</b> Analysis of Results</a></li>
<li class="chapter" data-level="3.5" data-path="bullets.html"><a href="bullets.html#communication-of-results-and-methods"><i class="fa fa-check"></i><b>3.5</b> Communication of Results and Methods</a><ul>
<li class="chapter" data-level="3.5.1" data-path="bullets.html"><a href="bullets.html#conference-presentations"><i class="fa fa-check"></i><b>3.5.1</b> Conference Presentations</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="bullets.html"><a href="bullets.html#people-involved"><i class="fa fa-check"></i><b>3.6</b> People involved</a><ul>
<li class="chapter" data-level="3.6.1" data-path="bullets.html"><a href="bullets.html#faculty"><i class="fa fa-check"></i><b>3.6.1</b> Faculty</a></li>
<li class="chapter" data-level="3.6.2" data-path="bullets.html"><a href="bullets.html#graduate-students"><i class="fa fa-check"></i><b>3.6.2</b> Graduate Students</a></li>
<li class="chapter" data-level="3.6.3" data-path="bullets.html"><a href="bullets.html#undergraduates"><i class="fa fa-check"></i><b>3.6.3</b> Undergraduates</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html"><i class="fa fa-check"></i><b>4</b> Project G: Handwriting (&amp; Signatures)</a><ul>
<li class="chapter" data-level="4.1" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html#data-collection-1"><i class="fa fa-check"></i><b>4.1</b> Data Collection</a></li>
<li class="chapter" data-level="4.2" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html#computational-tools-1"><i class="fa fa-check"></i><b>4.2</b> Computational Tools</a></li>
<li class="chapter" data-level="4.3" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html#statistical-analysis"><i class="fa fa-check"></i><b>4.3</b> Statistical Analysis</a><ul>
<li class="chapter" data-level="4.3.1" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html#clustering"><i class="fa fa-check"></i><b>4.3.1</b> Clustering</a></li>
<li class="chapter" data-level="4.3.2" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html#closed-set-modelling"><i class="fa fa-check"></i><b>4.3.2</b> Closed set modelling</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html#communication-of-results"><i class="fa fa-check"></i><b>4.4</b> Communication of Results</a><ul>
<li class="chapter" data-level="4.4.1" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html#papers"><i class="fa fa-check"></i><b>4.4.1</b> Papers</a></li>
<li class="chapter" data-level="4.4.2" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html#talks"><i class="fa fa-check"></i><b>4.4.2</b> Talks</a></li>
<li class="chapter" data-level="4.4.3" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html#posters"><i class="fa fa-check"></i><b>4.4.3</b> Posters</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html#people-involved-1"><i class="fa fa-check"></i><b>4.5</b> People involved</a><ul>
<li class="chapter" data-level="4.5.1" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html#faculty-1"><i class="fa fa-check"></i><b>4.5.1</b> Faculty</a></li>
<li class="chapter" data-level="4.5.2" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html#graduate-students-1"><i class="fa fa-check"></i><b>4.5.2</b> Graduate Students</a></li>
<li class="chapter" data-level="4.5.3" data-path="project-g-handwriting-signatures.html"><a href="project-g-handwriting-signatures.html#undergraduates-1"><i class="fa fa-check"></i><b>4.5.3</b> Undergraduates</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="glass.html"><a href="glass.html"><i class="fa fa-check"></i><b>5</b> Glass</a></li>
<li class="chapter" data-level="6" data-path="shoes.html"><a href="shoes.html"><i class="fa fa-check"></i><b>6</b> Shoes</a><ul>
<li class="chapter" data-level="6.1" data-path="shoes.html"><a href="shoes.html#longitudinal"><i class="fa fa-check"></i><b>6.1</b> Longitudinal Shoe Study</a><ul>
<li class="chapter" data-level="6.1.1" data-path="shoes.html"><a href="shoes.html#paper-describing-the-database"><i class="fa fa-check"></i><b>6.1.1</b> Paper describing the database</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="shoes.html"><a href="shoes.html#connor"><i class="fa fa-check"></i><b>6.2</b> Passive Shoe Recognition</a><ul>
<li class="chapter" data-level="6.2.1" data-path="shoes.html"><a href="shoes.html#nij-grant"><i class="fa fa-check"></i><b>6.2.1</b> NIJ Grant</a></li>
<li class="chapter" data-level="6.2.2" data-path="shoes.html"><a href="shoes.html#connor-convolutional-neural-network-for-outsole-recognition"><i class="fa fa-check"></i><b>6.2.2</b> CoNNOR: Convolutional Neural Network for Outsole Recognition</a></li>
<li class="chapter" data-level="6.2.3" data-path="shoes.html"><a href="shoes.html#spatial-integration"><i class="fa fa-check"></i><b>6.2.3</b> Spatial integration</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="shoes.html"><a href="shoes.html#maxclique"><i class="fa fa-check"></i><b>6.3</b> Maximum Clique Matching</a></li>
<li class="chapter" data-level="6.4" data-path="shoes.html"><a href="shoes.html#cocoa"><i class="fa fa-check"></i><b>6.4</b> Project Tread (formerly Cocoa Powder Citizen Science)</a></li>
<li class="chapter" data-level="6.5" data-path="shoes.html"><a href="shoes.html#d-shoe-recognition"><i class="fa fa-check"></i><b>6.5</b> 3d Shoe Recognition</a></li>
<li class="chapter" data-level="6.6" data-path="shoes.html"><a href="shoes.html#shoe-outsole-matching-using-image-descriptors"><i class="fa fa-check"></i><b>6.6</b> Shoe outsole matching using image descriptors</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="theoretical-foundations.html"><a href="theoretical-foundations.html"><i class="fa fa-check"></i><b>7</b> Theoretical foundations</a><ul>
<li class="chapter" data-level="7.1" data-path="theoretical-foundations.html"><a href="theoretical-foundations.html#common-source-vs-specific-source-comparison-via-information-theory"><i class="fa fa-check"></i><b>7.1</b> Common Source vs Specific Source Comparison via Information Theory</a><ul>
<li class="chapter" data-level="7.1.1" data-path="theoretical-foundations.html"><a href="theoretical-foundations.html#introduction"><i class="fa fa-check"></i><b>7.1.1</b> Introduction</a></li>
<li class="chapter" data-level="7.1.2" data-path="theoretical-foundations.html"><a href="theoretical-foundations.html#common-source-vs-specific-source-lr"><i class="fa fa-check"></i><b>7.1.2</b> Common Source vs Specific Source LR</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="theoretical-foundations.html"><a href="theoretical-foundations.html#score-based-likelihood-ratios-are-not-fundamentally-incoherent"><i class="fa fa-check"></i><b>7.2</b> Score-based Likelihood Ratios are not Fundamentally “Incoherent”</a><ul>
<li class="chapter" data-level="7.2.1" data-path="theoretical-foundations.html"><a href="theoretical-foundations.html#coherence"><i class="fa fa-check"></i><b>7.2.1</b> Coherence</a></li>
<li class="chapter" data-level="7.2.2" data-path="theoretical-foundations.html"><a href="theoretical-foundations.html#problems-with-arguments-showing-slrs-are-incoherent"><i class="fa fa-check"></i><b>7.2.2</b> Problems with arguments showing SLRs are incoherent</a></li>
<li class="chapter" data-level="7.2.3" data-path="theoretical-foundations.html"><a href="theoretical-foundations.html#example-of-a-coherent-slr-in-the-two-source-problem"><i class="fa fa-check"></i><b>7.2.3</b> Example of a coherent SLR in the two source problem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="outreach-activities.html"><a href="outreach-activities.html"><i class="fa fa-check"></i><b>8</b> Outreach activities</a><ul>
<li class="chapter" data-level="8.1" data-path="outreach-activities.html"><a href="outreach-activities.html#book-on-forensic-science-and-statistics"><i class="fa fa-check"></i><b>8.1</b> Book on Forensic Science and Statistics</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">This is us: making CSAFE stronger each week</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="shoes" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Shoes</h1>
<div id="longitudinal" class="section level2">
<h2><span class="header-section-number">6.1</span> Longitudinal Shoe Study</h2>
<p><a href="https://github.com/CSAFE-ISU/Longitudinal_Shoe_Study">Github repository</a></p>
<div id="paper-describing-the-database" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Paper describing the database</h3>
<p><a href="https://github.com/CSAFE-ISU/Longitudinal_Shoe_Study/tree/master/Paper">Paper subdirectory of Github repository</a></p>
<p>Goal:</p>
<ul>
<li>Describe experiment</li>
<li>Describe database function</li>
<li>Publicize data for analysis by others in the community</li>
</ul>
<div id="lss-paper-methods" class="section level4 unnumbered">
<h4>Methods and Data Description</h4>
<p>Methods and data description handed off to Alicia for editing</p>
</div>
<div id="lss-paper-analysis" class="section level4 unnumbered">
<h4>Data Analysis Tools</h4>
<ul>
<li>Working with the <code>EBImage</code> package - very fast processing of images</li>
</ul>
<div id="lss-paper-analysis-film" class="section level5 unnumbered">
<h5>Film and Powder Images</h5>
<details>
<p><summary>Analysis Summary: Create a mask via thresholding, clean it up, fill in mask holes, creating a shoe “region” mask. Apply this mask to the image, replacing any pixels outside the mask with the median background pixel. Additional thresholding and normalization can be applied if a binary image is more desireable. </summary></p>
<p><img src="images/shoes/longitudinal/Film_Demo_Orig.png" width = "100%"/></p>
<ol style="list-style-type: decimal">
<li>Create threshold mask
<ol style="list-style-type: lower-alpha">
<li>Blur image (circular/gaussian blur, diameter 15)<br />
<img src="images/shoes/longitudinal/Film_Demo_Blur_Init.png" width = "100%"/></li>
<li>Invert the image<br />
<img src="images/shoes/longitudinal/Film_Demo_Inv.png" width = "100%"/></li>
<li>Threshold image (adaptive threshold, 10 x 10 region, keep anything with an average higher than 0.025 from the mean)<br />
<img src="images/shoes/longitudinal/Film_Demo_Thresh_Init.png" width = "100%"/></li>
<li>Create mask<br />
Default parameters selected by visually screening several shoes:
<img src="images/shoes/longitudinal/Film_Demo_Parameter_Selection.png" width = "100%"/>
(default parameters rad1 = 5, rad2 = <span class="new">91</span>, proportion = 1.5*area of rad2 in px/area of image in px)<br />
<img src="images/shoes/longitudinal/Film_Demo_Mask.png" width = "100%"/>
<ol style="list-style-type: decimal">
<li>erode mask image (circle, diameter rad1)</li>
<li>dilate mask image (circle, diameter rad2)</li>
<li>label disjoint regions of the image</li>
<li>prune small image regions (area &lt; proportion parameter)</li>
</ol></li>
<li>Fill in mask holes<br />
<img src="images/shoes/longitudinal/Film_Demo_Hull.png" width = "100%"/></li>
<li>Expand mask to capture entire shoe region
<img src="images/shoes/longitudinal/Film_Demo_Mask_Expand.png" width = "100%"/>
<ol style="list-style-type: decimal">
<li>set background color</li>
<li>create dataframe of useful (non-background) pixels</li>
<li>fill in holes and concave regions in mask, then expand by expand_rad vertically and horizontally (similar to “convex hull”, but with additional expansion radius)</li>
</ol></li>
</ol></li>
<li><p>Mask image to remove extra variability unrelated to the shoe<br />
<img src="images/shoes/longitudinal/Film_Demo_Cleaned.png" width = "100%"/></p></li>
<li><p>Threshold masked image?<br />
Con: Lose grey information; Pro: fully remove background<br />
<img src="images/shoes/longitudinal/Film_Demo_Cleaned_Thresh.png" width = "100%"/></p></li>
<li><p>Compromise: Keep grey pixels from thresholded, masked image (e.g. use 3. as a mask), then renormalize<br />
<img src="images/shoes/longitudinal/Film_Demo_Cleaned_Balance.png" width = "100%"/></p></li>
</ol>
</details>
<div class="new">
<p>I’ve added the functions from last week to the <code>ShoeScrubR</code> package, which will hopefully contain methods for handling all of the different 2D shoe data from the longitudinal study.</p>
<p>Using that package, I tried the method out on a sequence of shoes over time to see what methods might best show wear. Each column shows a single left shoe over four timepoints. The shoes are the first 9 shoeIDs (e.g. 1 - 9).</p>
<details>
<summary>Original</summary>
<img src="images/shoes/longitudinal/Film_First9_Original.png" width="100%"/>
</details>
<details>
<summary>Cleaned</summary><br />
<img src="images/shoes/longitudinal/Film_First9_Cleaned.png" width="100%"/>
</details>
<details>
<summary>Cleaned and Thresholded</summary>
<img src="images/shoes/longitudinal/Film_First9_Cleaned_Thresholded.png" width="100%"/>
</details>
<p>Even with the cleaning methods… there is a lot of extra noise.</p>
</div>
<p>Next step: templating!</p>
<p>Basic framework:</p>
<details>
<summary>Create a template for each size and model combination</summary>
(using GIMP - if I could automate this, I wouldn’t need the template)
<img src="images/shoes/longitudinal/Templates_Equal_Size.png" width = "100%"/>
</details>
<details>
<p><summary>Intelligently brute force angle and position of template<br />
Goal: Maximize the number of black pixels in the image within the template region
</summary></p>
<ol style="list-style-type: decimal">
<li><p>Start with an image and a template mask</p></li>
<li><p>Blur, normalize, invert, and threshold the image<br />
<img src="images/shoes/longitudinal/Templates_Setup.png" width = "100%"/></p></li>
<li><p>Naively align the “centers” of the two images (avg of white pixel row/cols). To make this calculation comparable, do some very crude dilation/erosion (that may or may not generalize that well) to fill in the image a bit.<br />
<img src="images/shoes/longitudinal/Templates_Naive_Centering.png" width = "100%"/><br />
Then make the aligned center the actual center of the image via padding. (This is the 1st time we have modified the actual image beyond thresholding and color changes).</p></li>
</ol>
<div class="new">
<ol start="4" style="list-style-type: decimal">
<li>~~Create a new mask to sample the image (and the mask) radially. ~~ This doesn’t work when the object isn’t a solid entity :(</li>
</ol>
<p>New Option: Use image pyramids and brute-force alignment, starting off with an estimated rotation angle of <span class="math inline">\(\theta\)</span> from principal components<br />
<img src="images/shoes/longitudinal/ImagePyramids.png" width = "100%"/><br />
<img src="images/shoes/longitudinal/MaskPyramids.png" width = "100%"/><br />
<img src="images/shoes/longitudinal/ShiftPyramids.png" width = "100%"/></p>
<ol start="5" style="list-style-type: decimal">
<li>Brute force full-size image to get finer alignment.</li>
</ol>
</div>
<ol start="6" style="list-style-type: decimal">
<li>Remove anything not in the mask region.</li>
</ol>
</details>
</div>
<div id="lss-paper-analysis-wear" class="section level5 unnumbered">
<h5>Wear Characterization</h5>
<p>Ideas:</p>
<ul>
<li>average intensity of cleaned image</li>
<li>length of border/edges detected</li>
</ul>
</div>
</div>
</div>
</div>
<div id="connor" class="section level2">
<h2><span class="header-section-number">6.2</span> Passive Shoe Recognition</h2>
<div id="nij-grant" class="section level3">
<h3><span class="header-section-number">6.2.1</span> NIJ Grant</h3>
<div class="new">
<p>Grant scope: Build the shoe scanner, develop an automatic recognition algorithm for geometric design elements, test the scanner in locations around Ames.</p>
<p>Status: Funded! Next challenge: Figuring out how to transfer it to UNL.</p>
</div>
</div>
<div id="connor-convolutional-neural-network-for-outsole-recognition" class="section level3">
<h3><span class="header-section-number">6.2.2</span> CoNNOR: Convolutional Neural Network for Outsole Recognition</h3>
<p><strong>Project Overview</strong></p>
<ul>
<li>Label images of shoes according to geometric classification scheme</li>
<li>Use convolutional base of pretrained CNN VGG16 and train a new classifier on labeled features</li>
<li>Eventually, acquire real data passively and use CoNNOR to assess feature similarities and frequencies</li>
</ul>
<p><a href="https://lib.dr.iastate.edu/creativecomponents/264/">Link to submitted Creative Component on CoNNOR</a></p>
<p><a href="https://github.com/srvanderplas/CoNNORFSI">Github repository for paper submitted to Forensic Science International</a></p>
<p><strong>Exploring new directions:</strong></p>
<ul>
<li>Truncate convolutional base and train random forest on features
<ul>
<li>Could replace fully connected layers of neural net as classifier</li>
<li>Importance score can filter/reduce the number of features</li>
<li><em>Block 4 random forest training terminated after one week :( </em></li>
<li><em>Block 5 currently training for two different random forest packages (randomForest and ranger)</em></li>
<li><em>If new models take more than 1-2 weeks, will look into subsampling techniques.</em></li>
</ul></li>
<li><em>Spatial integration</em>
<ul>
<li><em>Model is currently set up to take in 256x256 pixels</em></li>
<li><em>Try taking in full shoe using a sliding window of size 256x256</em></li>
<li><em>View class predictions spatially</em></li>
</ul></li>
<li>Fully convolutional networks (FCNs)
<ul>
<li>Unsupervised segmentation to assess current classification scheme</li>
<li>Handle whole shoe image of any size (instead of only 256x256 pixel images)</li>
</ul></li>
</ul>
<p><strong>References for CNNs and FCNs</strong></p>
<p><a href="https://stats.stackexchange.com/questions/266075/patch-wise-training-and-fully-convolutional-training-in-fully-convolutional-neur">Stack Exchange post explaining patchwise training</a></p>
<p><a href="https://ieeexplore.ieee.org/abstract/document/6338939">“Learning Hierarchical Features for Scene Labeling”</a>: describes an application of multi-scale CNNs and image pyramids</p>
<p><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.8646">“Pyramid methods in image processing”</a>: classic paper from 1984 explaining pyramid methods</p>
<p><a href="https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf">“Fully Convolutional Networks for Semantic Segmentation”</a></p>
<p><a href="https://arxiv.org/pdf/1711.08506.pdf">“W-Net: A Deep Model for Fully Unsupervised Image Segmentation”</a></p>
</div>
<div id="spatial-integration" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Spatial integration</h3>
<div class="new">
<p>The overhead costs of going fully convolutional are high; CNN papers are opaque, and many supervised techniques require fully labeled data for semantic segmentation (i.e., label every pixel). Moreover, complex models (for both supervised and unsupervised tequniques) are often only available in Python, and there are a large number of GitHub repositories of mixed quality and reliability. Filtering for quality, understanding code structures, and implementing them on HPC are all enormous tasks on their own.</p>
<p>In the meantime, it is much easier (relatively speaking) to use our existing framework of 256x256 square pixel images, for which we have generated thousands of labeled images and have already trained and improved domain-specific models. Currently, I have code working to automatically crop image borders, chop the image into 256x256 pixels (padding the image when appropriate) and correct the contrast on the individual images.</p>
</div>
<p><img src="images/shoes/neuralnets/chop.PNG" width = "100%"/><br />
<img src="images/shoes/neuralnets/contrastcorrect.PNG" width = "100%"/></p>
<p>I hoped to have some cool visualizations to show today. Unfortunately, model predictions are behaving very strangely, and I haven’t been able to figure out why… All classes are predicting to zero, except quadrilaterals.</p>
<p><img src="images/shoes/neuralnets/quad_predictions.PNG" width = "50%"/></p>
<p>Possible issues:</p>
<ul>
<li><del>
The specific shoe is behaving strangely
</del>
The issue persists for multiple shoes</li>
<li><del>
Using a different package to read in the image changes the extracted features
</del>
The issue persists when I try using the original image reading function</li>
<li><del>
Contrast correction changes predictions
</del>
The issue exists for images both with and without contrast correction</li>
<li><del>
Model trained incorrectly
</del>
The <a href="https://bigfoot.csafe.iastate.edu:442/tiltonm/NNPreview/">Shiny app</a> shows predictions on the test set are behaving as expected</li>
<li>Bigfoot is angry?</li>
</ul>
<p>Bottom line: CNN features are NOT interpretable, which makes them VERY hard to debug.</p>
</div>
</div>
<div id="maxclique" class="section level2">
<h2><span class="header-section-number">6.3</span> Maximum Clique Matching</h2>
</div>
<div id="cocoa" class="section level2">
<h2><span class="header-section-number">6.4</span> Project Tread (formerly Cocoa Powder Citizen Science)</h2>
<p>Project Tread, modified from <a href="https://www.dundee.ac.uk/leverhulme/citizenscience/details/sole-searching.php">Leverhulme Institute’s Sole Searching</a>, is a developing CSAFE project with the goals of engaging community participation in forensic research and acquiring shoe print data that may be useful in future analyses.</p>
<p>In progress:</p>
<ul>
<li>Review <a href="https://forensicstats.org/project-tread/">procedures</a> and IRB documents written by James</li>
<li>Perhaps modify procedures, then bribe some friends into helping me test them :)
<ul>
<li>Test for length, clarity, ease, etc.</li>
</ul></li>
<li>Be involved in set up of data collection site (through CSSM)</li>
</ul>
<div class="new">
<h4 id="comparing-the-procedures"><span class="header-section-number">6.4</span> Comparing the procedures</h4>
<table>
<thead>
<tr class="header">
<th>Procedure</th>
<th>Leverhulme</th>
<th>CSAFE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>‘Before’ Pictures</td>
<td>4 per shoe</td>
<td>15 per shoe</td>
</tr>
<tr class="even">
<td>Paper</td>
<td>Letter (larger)</td>
<td>Tape printer paper</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Actions</td>
<td>Run, jump, walk</td>
<td>Step, hop</td>
</tr>
<tr class="odd">
<td>Replicates</td>
<td>6 per shoe</td>
<td>9 per shoe</td>
</tr>
<tr class="even">
<td>‘After’ Pictures</td>
<td>1 pic per print</td>
<td>3 pics per print</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Total number prints</td>
<td>18 per shoe</td>
<td>18 per shoe</td>
</tr>
<tr class="odd">
<td>Total number images</td>
<td>18 per shoe</td>
<td>54 per shoe</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="d-shoe-recognition" class="section level2">
<h2><span class="header-section-number">6.5</span> 3d Shoe Recognition</h2>
<p>The set up</p>
<p>What we have tried</p>
<p>What we are doing now
- Transforming the mesh objects to points aligned by the center of mass to overlay them detecting difference.
<img src="images/shoes/3dshoes/AlignShoeTest.png" width="100%"/>
- Problems
- Isnt aligning properly as you can see
- Next
- angle transformations</p>
</div>
<div id="shoe-outsole-matching-using-image-descriptors" class="section level2">
<h2><span class="header-section-number">6.6</span> Shoe outsole matching using image descriptors</h2>
<p>Previously, features such as edge, corner, SURF were extracted to match shoeprints. The goal of this project is to find other image descriptors as image features for shoe print matching.</p>
<p><strong>Image descriptors</strong></p>
<ul>
<li>SURF(Speeded Up Robust Features)- blobs</li>
<li>KAZE - blobs</li>
<li>ORB(Oriented FAST and Rotated BRIEF)- corners</li>
</ul>
<p><img src="images/soyoung/nike_kaze_orb_surf.png" width="100%"/></p>
<p><img src="images/soyoung/adidas_kaze_orb_surf.png" width="100%"/></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="glass.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="theoretical-foundations.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-shoes.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
